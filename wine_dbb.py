# -*- coding: utf-8 -*-
"""Wine_DBB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e1clmYQpVU5BZWL_Dn7jCesPVdgdJ-mE
"""

#Import dataset
from sklearn import datasets
import pandas as pd
import numpy as np

wine = datasets.load_wine()

df = pd.DataFrame(wine.data, columns=wine.feature_names)
df['target'] = wine.target
df

#separate features and targets
X = wine.data
y = wine.target

"""Exploratory Data Analysis"""

df.info()

df['target'].value_counts()

#check for duplicate data
jumlah_duplikat = df.duplicated().sum()
print(f"Jumlah duplikat: {jumlah_duplikat}")

#check missing value
df.isnull().sum()

#check normal distribution
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats
feature = df["alcohol"]

# Plot QQ-Plot
stats.probplot(feature, dist="norm", plot=plt)
plt.title("QQ Plot untuk Fitur Alcohol")
plt.show()

#Create feature and target dataframes with pandas
df_X = pd.DataFrame(X, columns=wine.feature_names)
df_y = pd.Series(y, name='target')

df_X

#separate train data and test data
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

"""Scaling with Standarization because the data follow normal distribution

"""

#feature scaling - Standarization
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train[:, :] = scaler.fit_transform(X_train[:, :])
X_test[:, :] = scaler.transform(X_test[:, :])

#Checking X after standarization
df_train = pd.DataFrame(X_train)
df_train

"""Loop to check which n_neighbors value is the best"""

#loop to check which n_neighbors value is the best
from sklearn.neighbors import KNeighborsClassifier
error_rate = []
for i in range(1, 40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error_rate.append(np.mean(pred_i != y_test))

print('Minimum error rate = ', min(error_rate), 'pada n_neighbors = ',error_rate.index(min(error_rate)) + 1)

#analysis with the K Nearest Neighbors algorithm with the best n_neighbors value

knn = KNeighborsClassifier(n_neighbors=6)
knn.fit(X_train, y_train)
pred = knn.predict(X_test)

"""Evaluation"""

#checking the accuracy of K Nearest Neighbors
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_auc_score
akurasi_knn = classification_report(y_test, pred)
skor_akurasi_knn = accuracy_score(y_test, pred)

print("Classification Report - K Nearest Neighbors")
print(akurasi_knn)
print('Skor akurasi = ', skor_akurasi_knn)

#create a confusion matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Reds",
            xticklabels=wine.target_names, yticklabels=wine.target_names)
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.title("Confusion Matrix")
plt.show()

#Calculates the correlation of each feature with the target
corr_matrix = df.corr()

#Displays the correlation of features to the target
print(corr_matrix['target'].sort_values(ascending=False))

# Visualize Heatmap Correlation
plt.figure(figsize=(10,6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.show()